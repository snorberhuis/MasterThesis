\chapter{Problem Description}
The essence of a distributed system is that every node performs tasks for other nodes.
With open systems, where every one can join, an unsolved problem is how to prevent nodes
from only consuming and not contributing to the system.
Our work is beneficial in solving this problem.

In this chapter the problem will be described of how to decide to perform a task for a peer.
In such a way that prevents that peer from freeloading.
The problem will first be explained in a simplified form.
Using this simplification, the problem will be transformed gradually
to the real world problem faced in distributed systems today.

\section{Deciding to help}
The field of game theory has studied for decades this problem of how
nodes can decide to cooperate with a peer or decide not to help a peer and defect.
This is the traditional Prisoner's Dilemma 
and we will explain this dilemma\cite{Nowak-PrisonerDilemma}\cite{Lai-Incentives}.
Nodes can help each other at a cost, a negative utility, 
but the recipient of the help will receive a beneficial utility from the help.
The benefit received is greater than the cost and is denoted by $R$ for reward.
But if one node chooses to not help the other node,
 then he will still receive a beneficial utility and at no cost, $T$ for temptation.
The node that provided the aid will now receive no benefit and only incur a cost $C$.
If both nodes choose to not help each other, 
then they will both receive a penalty $P$, which is higher then the cost of helping each other.

This dilemma can be repeated several times with the same nodes and is the Iterated Prisoner's Dilemma.
Each time both nodes will have to decide if it will help the other node.
The utility received can be seen in Table \ref{tab:pd-um}.

\begin{table}
\center
	\begin{tabular}{l|ll}
	A\textbackslash B       & cooperate  & defect     \\ \hline
	cooperate & $R_A /R_B$ & $T_A /C_B$ \\
	defect    & $T_A /C_B$ & $P_A /P_B$
	\end{tabular}
\caption{Prisoner's Dilemma utility matrix}
\label{tab:pd-um}
\end{table}

A rational node wants to receive maximum benefit at a minimal cost.
The node will follow a strategy that he believes will achieve this.
At first it might seem that a node will always choose to defect,
because it will never incur a cost and receive maximal benefit.
But the other node will be reluctant to help a node if the aid is never returned.
Simple strategies, like tit-for-tat or win-stay, lose-shift, suffice in the Iterated Prisoner's Dilemma
and will perform well\cite{Nowak-Cooperation}.

In a large scale, distributed system, this dilemma occurs with every interaction between nodes.
The node can already be familiar with the peer,
but more often the peer will be a peer the node has not interacted with before.
A further complication is that help is one way and can no longer be exchanged.
This complication excludes the direct opportunity to barter for help 
or to barter for help in the future\cite{Lai-Incentives}.
The performance of the tit-for-tat or win-stay, lose-shift strategies
quickly deteriorate in such a situation.

For a node it is easier to abuse the generosity of others in this more anonymous situation.
Nodes that help others will be penalized through the cost they incur
and incentivized to adopt the malicious behavior themselves.
Nodes in general will become more reluctant to help nodes\cite{Nowak-PrisonerDilemma}.
In the end no node will help another and all nodes will receive a penalty.
This is commonly called the Tragedy of the Commons in the literature \cite{hardin-tragedy}.
The whole network will actually receive more benefit in total if everyone would corporates.
But nodes have no way of knowing if the peer they meet are willing to help.
A lack of altruism and selfishness will become a problem 
and will cause the network to be suspectible to freeriding.

\section{History of decisions}

In the Iterated Prisoner's Dilemma the history of the previous transactions can be used 
to see if a node helped others in the past.
The simple strategies, previously mentioned, use a history to improve performance
to avoid freeriding.
But this private history is not effective to achieve high overall utility in distributed systems,
because the peers are often interacted with for the first time.
No history is known for these peers.
A public history of node, containing every previous interaction, is necessary to prevent abuse
and is able to achieve high overall utility\cite{Lai-Incentives}.

A history can be used to create a currency or a reputation system
and can be seen as a bookkeeping system.
The node providing help will receive a boost in currency or a beneficial reputation.
The currency or reputation can be used in the future to receive aid.
In a currency system, receiving help will transfer currency to the helper.
In a reputation system, only nodes with a sufficiently good reputation will be helped.

The currency or reputation has to be made publicly available to all nodes in the network.
But a node publicizing to hold a certain reputation is not sufficient as it is not trustworthy.
So a interaction history, that contains every prior interaction a node has conducted, is publicized.
Nodes can cross-reference the interaction history with other nodes and calculate the amount of currency 
or the reputation that a node has.
Based upon this calculation, the node can decide to provide aid or not.

The interaction history has to be distributed among the nodes in the network
to become publicly available.
Efficient distribution protocols are a difficult challenge themselves and outside the problem scope.
But distribution is worth mentioning, because it puts constraints on the interaction history.
The interaction history has to be distributable in an efficient manner.
Only if it meets these constraints, will an interaction history be usable in a distributed system.

\section{Tamper-proof interaction history to facilitate trust}
Interaction histories only prevent direct abuse of the generosity of the nodes.
A malicious node can still try to tamper with the interaction history.
An example of a type of these attacks are double spending attacks\cite{Nakamoto-bitcoin},
where an interaction is altered.
But a node can also try to deny an interaction.
The interaction history has to be resilient to attacks that tamper the interaction history, 
or no one will trust the history. 
A reputation or digital currency system requires a level of trust in the system to function.
The challenge of this thesis is to create a tamper-proof interaction history.

A system cannot be fully secure, 
but still a reasonable certainty can be achieved that no tampering of the interaction history can occur.
Reasonable certainty is for example that no attack can happen 
if more than half of the network consists of honest nodes.

\section{Aim of this thesis}
\label{pb-aim}
The overall aim of this thesis is to design, implement and conduct experiments with a tamper-proof interaction history
implemented within Tribler.
The interaction history will keep a history of the amount of data downloaded between nodes in the network.
An incremental approach is taken with this thesis as the first step in creating a fully tamper-proof interaction history.
Several more steps are needed and these steps are explained in chapter \ref{problems}.
